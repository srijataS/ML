{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56087490",
   "metadata": {},
   "source": [
    "Question 4:\tPlease modify the above dataset (in question 3) to answer whether the house will sell for 180000 or not and use the appropriate algorithm (from question 1 or 2) to learn a model from the training set and answer whether the prices > 180000 or not for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ee3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from math import sqrt\n",
    "from csv import reader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from random import seed\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c60857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with numerical feature and droping NA value columns\n",
    "\n",
    "def data_numerical_feature(dataset):\n",
    "    pct_null = dataset.isnull().sum() / len(dataset)\n",
    "    missing_features = pct_null[pct_null > 0.00].index\n",
    "    #print('Number of missing_features: ', missing_features)\n",
    "    dataset.drop(missing_features, axis=1, inplace=True)\n",
    "    \n",
    "    numerical_features=[feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\n",
    "    #print('Number of numerical variables: ', len(numerical_features))\n",
    "    \n",
    "    ds = dataset[numerical_features]    \n",
    "    ds.drop(['Id'], axis=1, inplace=True)   \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e39cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe5af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94d9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c9213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef235ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(0,len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56a47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:            \n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a13cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with coefficients\n",
    "def predict(row, w):\n",
    "    yhat = w[-1]                           # bias is at dimnesion 0\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += w[i] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196b6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate logistic regression coefficients \n",
    "#using stochastic gradient descent\n",
    "def weights_sgd(train, l_rate, n_epoch):\n",
    "    w = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, w)\n",
    "            error = row[-1] - yhat\n",
    "            sum_error += error**2\n",
    "            w[-1] = w[-1] + l_rate * \\\n",
    "            error * yhat * (1.0 - yhat)\n",
    "            for i in range(len(row)-1):\n",
    "                w[i] = w[i] + l_rate * error * \\\n",
    "                yhat * (1.0 - yhat) * row[i]\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a29322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Algorithm With Stochastic Gradient Descent\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    w = weights_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        yhat = predict(row, w)\n",
    "        yhat = round(yhat)\n",
    "        predictions.append(yhat)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777ff5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srija\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.030, error=256.543\n",
      ">epoch=1, lrate=0.030, error=208.759\n",
      ">epoch=2, lrate=0.030, error=181.144\n",
      ">epoch=3, lrate=0.030, error=163.786\n",
      ">epoch=4, lrate=0.030, error=151.898\n",
      ">epoch=5, lrate=0.030, error=143.195\n",
      ">epoch=6, lrate=0.030, error=136.501\n",
      ">epoch=7, lrate=0.030, error=131.156\n",
      ">epoch=8, lrate=0.030, error=126.763\n",
      ">epoch=9, lrate=0.030, error=123.070\n",
      ">epoch=10, lrate=0.030, error=119.907\n",
      ">epoch=11, lrate=0.030, error=117.158\n",
      ">epoch=12, lrate=0.030, error=114.739\n",
      ">epoch=13, lrate=0.030, error=112.586\n",
      ">epoch=14, lrate=0.030, error=110.655\n",
      ">epoch=15, lrate=0.030, error=108.907\n",
      ">epoch=16, lrate=0.030, error=107.314\n",
      ">epoch=17, lrate=0.030, error=105.855\n",
      ">epoch=18, lrate=0.030, error=104.510\n",
      ">epoch=19, lrate=0.030, error=103.265\n",
      ">epoch=20, lrate=0.030, error=102.106\n",
      ">epoch=21, lrate=0.030, error=101.025\n",
      ">epoch=22, lrate=0.030, error=100.011\n",
      ">epoch=23, lrate=0.030, error=99.058\n",
      ">epoch=24, lrate=0.030, error=98.159\n",
      ">epoch=25, lrate=0.030, error=97.310\n",
      ">epoch=26, lrate=0.030, error=96.504\n",
      ">epoch=27, lrate=0.030, error=95.738\n",
      ">epoch=28, lrate=0.030, error=95.009\n",
      ">epoch=29, lrate=0.030, error=94.314\n",
      ">epoch=30, lrate=0.030, error=93.648\n",
      ">epoch=31, lrate=0.030, error=93.011\n",
      ">epoch=32, lrate=0.030, error=92.400\n",
      ">epoch=33, lrate=0.030, error=91.813\n",
      ">epoch=34, lrate=0.030, error=91.248\n",
      ">epoch=35, lrate=0.030, error=90.704\n",
      ">epoch=36, lrate=0.030, error=90.179\n",
      ">epoch=37, lrate=0.030, error=89.672\n",
      ">epoch=38, lrate=0.030, error=89.182\n",
      ">epoch=39, lrate=0.030, error=88.708\n",
      ">epoch=40, lrate=0.030, error=88.248\n",
      ">epoch=41, lrate=0.030, error=87.802\n",
      ">epoch=42, lrate=0.030, error=87.370\n",
      ">epoch=43, lrate=0.030, error=86.950\n",
      ">epoch=44, lrate=0.030, error=86.541\n",
      ">epoch=45, lrate=0.030, error=86.144\n",
      ">epoch=46, lrate=0.030, error=85.757\n",
      ">epoch=47, lrate=0.030, error=85.380\n",
      ">epoch=48, lrate=0.030, error=85.012\n",
      ">epoch=49, lrate=0.030, error=84.654\n",
      ">epoch=0, lrate=0.030, error=255.111\n",
      ">epoch=1, lrate=0.030, error=207.101\n",
      ">epoch=2, lrate=0.030, error=179.660\n",
      ">epoch=3, lrate=0.030, error=162.372\n",
      ">epoch=4, lrate=0.030, error=150.492\n",
      ">epoch=5, lrate=0.030, error=141.767\n",
      ">epoch=6, lrate=0.030, error=135.037\n",
      ">epoch=7, lrate=0.030, error=129.648\n",
      ">epoch=8, lrate=0.030, error=125.209\n",
      ">epoch=9, lrate=0.030, error=121.470\n",
      ">epoch=10, lrate=0.030, error=118.263\n",
      ">epoch=11, lrate=0.030, error=115.471\n",
      ">epoch=12, lrate=0.030, error=113.010\n",
      ">epoch=13, lrate=0.030, error=110.819\n",
      ">epoch=14, lrate=0.030, error=108.851\n",
      ">epoch=15, lrate=0.030, error=107.069\n",
      ">epoch=16, lrate=0.030, error=105.444\n",
      ">epoch=17, lrate=0.030, error=103.955\n",
      ">epoch=18, lrate=0.030, error=102.582\n",
      ">epoch=19, lrate=0.030, error=101.311\n",
      ">epoch=20, lrate=0.030, error=100.128\n",
      ">epoch=21, lrate=0.030, error=99.024\n",
      ">epoch=22, lrate=0.030, error=97.990\n",
      ">epoch=23, lrate=0.030, error=97.019\n",
      ">epoch=24, lrate=0.030, error=96.103\n",
      ">epoch=25, lrate=0.030, error=95.237\n",
      ">epoch=26, lrate=0.030, error=94.417\n",
      ">epoch=27, lrate=0.030, error=93.639\n",
      ">epoch=28, lrate=0.030, error=92.898\n",
      ">epoch=29, lrate=0.030, error=92.192\n",
      ">epoch=30, lrate=0.030, error=91.518\n",
      ">epoch=31, lrate=0.030, error=90.873\n",
      ">epoch=32, lrate=0.030, error=90.255\n",
      ">epoch=33, lrate=0.030, error=89.662\n",
      ">epoch=34, lrate=0.030, error=89.092\n",
      ">epoch=35, lrate=0.030, error=88.544\n",
      ">epoch=36, lrate=0.030, error=88.016\n",
      ">epoch=37, lrate=0.030, error=87.506\n",
      ">epoch=38, lrate=0.030, error=87.015\n",
      ">epoch=39, lrate=0.030, error=86.540\n",
      ">epoch=40, lrate=0.030, error=86.080\n",
      ">epoch=41, lrate=0.030, error=85.635\n",
      ">epoch=42, lrate=0.030, error=85.204\n",
      ">epoch=43, lrate=0.030, error=84.785\n",
      ">epoch=44, lrate=0.030, error=84.379\n",
      ">epoch=45, lrate=0.030, error=83.985\n",
      ">epoch=46, lrate=0.030, error=83.601\n",
      ">epoch=47, lrate=0.030, error=83.228\n",
      ">epoch=48, lrate=0.030, error=82.865\n",
      ">epoch=49, lrate=0.030, error=82.511\n",
      ">epoch=0, lrate=0.030, error=256.941\n",
      ">epoch=1, lrate=0.030, error=209.853\n",
      ">epoch=2, lrate=0.030, error=182.456\n",
      ">epoch=3, lrate=0.030, error=165.046\n",
      ">epoch=4, lrate=0.030, error=153.047\n",
      ">epoch=5, lrate=0.030, error=144.233\n",
      ">epoch=6, lrate=0.030, error=137.442\n",
      ">epoch=7, lrate=0.030, error=132.014\n",
      ">epoch=8, lrate=0.030, error=127.551\n",
      ">epoch=9, lrate=0.030, error=123.798\n",
      ">epoch=10, lrate=0.030, error=120.585\n",
      ">epoch=11, lrate=0.030, error=117.792\n",
      ">epoch=12, lrate=0.030, error=115.334\n",
      ">epoch=13, lrate=0.030, error=113.147\n",
      ">epoch=14, lrate=0.030, error=111.185\n",
      ">epoch=15, lrate=0.030, error=109.409\n",
      ">epoch=16, lrate=0.030, error=107.792\n",
      ">epoch=17, lrate=0.030, error=106.309\n",
      ">epoch=18, lrate=0.030, error=104.943\n",
      ">epoch=19, lrate=0.030, error=103.678\n",
      ">epoch=20, lrate=0.030, error=102.502\n",
      ">epoch=21, lrate=0.030, error=101.403\n",
      ">epoch=22, lrate=0.030, error=100.374\n",
      ">epoch=23, lrate=0.030, error=99.406\n",
      ">epoch=24, lrate=0.030, error=98.493\n",
      ">epoch=25, lrate=0.030, error=97.630\n",
      ">epoch=26, lrate=0.030, error=96.812\n",
      ">epoch=27, lrate=0.030, error=96.035\n",
      ">epoch=28, lrate=0.030, error=95.295\n",
      ">epoch=29, lrate=0.030, error=94.589\n",
      ">epoch=30, lrate=0.030, error=93.914\n",
      ">epoch=31, lrate=0.030, error=93.267\n",
      ">epoch=32, lrate=0.030, error=92.647\n",
      ">epoch=33, lrate=0.030, error=92.052\n",
      ">epoch=34, lrate=0.030, error=91.479\n",
      ">epoch=35, lrate=0.030, error=90.927\n",
      ">epoch=36, lrate=0.030, error=90.394\n",
      ">epoch=37, lrate=0.030, error=89.880\n",
      ">epoch=38, lrate=0.030, error=89.384\n",
      ">epoch=39, lrate=0.030, error=88.903\n",
      ">epoch=40, lrate=0.030, error=88.437\n",
      ">epoch=41, lrate=0.030, error=87.986\n",
      ">epoch=42, lrate=0.030, error=87.548\n",
      ">epoch=43, lrate=0.030, error=87.122\n",
      ">epoch=44, lrate=0.030, error=86.709\n",
      ">epoch=45, lrate=0.030, error=86.306\n",
      ">epoch=46, lrate=0.030, error=85.915\n",
      ">epoch=47, lrate=0.030, error=85.533\n",
      ">epoch=48, lrate=0.030, error=85.162\n",
      ">epoch=49, lrate=0.030, error=84.799\n",
      ">epoch=0, lrate=0.030, error=256.022\n",
      ">epoch=1, lrate=0.030, error=208.402\n",
      ">epoch=2, lrate=0.030, error=180.840\n",
      ">epoch=3, lrate=0.030, error=163.422\n",
      ">epoch=4, lrate=0.030, error=151.477\n",
      ">epoch=5, lrate=0.030, error=142.741\n",
      ">epoch=6, lrate=0.030, error=136.035\n",
      ">epoch=7, lrate=0.030, error=130.693\n",
      ">epoch=8, lrate=0.030, error=126.314\n",
      ">epoch=9, lrate=0.030, error=122.641\n",
      ">epoch=10, lrate=0.030, error=119.502\n",
      ">epoch=11, lrate=0.030, error=116.779\n",
      ">epoch=12, lrate=0.030, error=114.386\n",
      ">epoch=13, lrate=0.030, error=112.260\n",
      ">epoch=14, lrate=0.030, error=110.355\n",
      ">epoch=15, lrate=0.030, error=108.632\n",
      ">epoch=16, lrate=0.030, error=107.064\n",
      ">epoch=17, lrate=0.030, error=105.628\n",
      ">epoch=18, lrate=0.030, error=104.305\n",
      ">epoch=19, lrate=0.030, error=103.081\n",
      ">epoch=20, lrate=0.030, error=101.942\n",
      ">epoch=21, lrate=0.030, error=100.879\n",
      ">epoch=22, lrate=0.030, error=99.884\n",
      ">epoch=23, lrate=0.030, error=98.948\n",
      ">epoch=24, lrate=0.030, error=98.065\n",
      ">epoch=25, lrate=0.030, error=97.231\n",
      ">epoch=26, lrate=0.030, error=96.439\n",
      ">epoch=27, lrate=0.030, error=95.688\n",
      ">epoch=28, lrate=0.030, error=94.972\n",
      ">epoch=29, lrate=0.030, error=94.289\n",
      ">epoch=30, lrate=0.030, error=93.636\n",
      ">epoch=31, lrate=0.030, error=93.010\n",
      ">epoch=32, lrate=0.030, error=92.410\n",
      ">epoch=33, lrate=0.030, error=91.834\n",
      ">epoch=34, lrate=0.030, error=91.279\n",
      ">epoch=35, lrate=0.030, error=90.745\n",
      ">epoch=36, lrate=0.030, error=90.229\n",
      ">epoch=37, lrate=0.030, error=89.731\n",
      ">epoch=38, lrate=0.030, error=89.250\n",
      ">epoch=39, lrate=0.030, error=88.784\n",
      ">epoch=40, lrate=0.030, error=88.333\n",
      ">epoch=41, lrate=0.030, error=87.896\n",
      ">epoch=42, lrate=0.030, error=87.471\n",
      ">epoch=43, lrate=0.030, error=87.059\n",
      ">epoch=44, lrate=0.030, error=86.658\n",
      ">epoch=45, lrate=0.030, error=86.268\n",
      ">epoch=46, lrate=0.030, error=85.888\n",
      ">epoch=47, lrate=0.030, error=85.518\n",
      ">epoch=48, lrate=0.030, error=85.157\n",
      ">epoch=49, lrate=0.030, error=84.806\n",
      ">epoch=0, lrate=0.030, error=258.128\n",
      ">epoch=1, lrate=0.030, error=211.674\n",
      ">epoch=2, lrate=0.030, error=184.748\n",
      ">epoch=3, lrate=0.030, error=167.661\n",
      ">epoch=4, lrate=0.030, error=155.882\n",
      ">epoch=5, lrate=0.030, error=147.224\n",
      ">epoch=6, lrate=0.030, error=140.547\n",
      ">epoch=7, lrate=0.030, error=135.207\n",
      ">epoch=8, lrate=0.030, error=130.814\n",
      ">epoch=9, lrate=0.030, error=127.118\n",
      ">epoch=10, lrate=0.030, error=123.951\n",
      ">epoch=11, lrate=0.030, error=121.199\n",
      ">epoch=12, lrate=0.030, error=118.776\n",
      ">epoch=13, lrate=0.030, error=116.621\n",
      ">epoch=14, lrate=0.030, error=114.686\n",
      ">epoch=15, lrate=0.030, error=112.936\n",
      ">epoch=16, lrate=0.030, error=111.341\n",
      ">epoch=17, lrate=0.030, error=109.880\n",
      ">epoch=18, lrate=0.030, error=108.534\n",
      ">epoch=19, lrate=0.030, error=107.288\n",
      ">epoch=20, lrate=0.030, error=106.129\n",
      ">epoch=21, lrate=0.030, error=105.046\n",
      ">epoch=22, lrate=0.030, error=104.032\n",
      ">epoch=23, lrate=0.030, error=103.079\n",
      ">epoch=24, lrate=0.030, error=102.180\n",
      ">epoch=25, lrate=0.030, error=101.330\n",
      ">epoch=26, lrate=0.030, error=100.524\n",
      ">epoch=27, lrate=0.030, error=99.758\n",
      ">epoch=28, lrate=0.030, error=99.029\n",
      ">epoch=29, lrate=0.030, error=98.333\n",
      ">epoch=30, lrate=0.030, error=97.668\n",
      ">epoch=31, lrate=0.030, error=97.030\n",
      ">epoch=32, lrate=0.030, error=96.419\n",
      ">epoch=33, lrate=0.030, error=95.832\n",
      ">epoch=34, lrate=0.030, error=95.266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=35, lrate=0.030, error=94.722\n",
      ">epoch=36, lrate=0.030, error=94.196\n",
      ">epoch=37, lrate=0.030, error=93.689\n",
      ">epoch=38, lrate=0.030, error=93.198\n",
      ">epoch=39, lrate=0.030, error=92.723\n",
      ">epoch=40, lrate=0.030, error=92.263\n",
      ">epoch=41, lrate=0.030, error=91.817\n",
      ">epoch=42, lrate=0.030, error=91.383\n",
      ">epoch=43, lrate=0.030, error=90.962\n",
      ">epoch=44, lrate=0.030, error=90.553\n",
      ">epoch=45, lrate=0.030, error=90.154\n",
      ">epoch=46, lrate=0.030, error=89.766\n",
      ">epoch=47, lrate=0.030, error=89.388\n",
      ">epoch=48, lrate=0.030, error=89.019\n",
      ">epoch=49, lrate=0.030, error=88.660\n",
      "Scores: [91.78082191780823, 88.35616438356165, 90.41095890410958, 91.0958904109589, 93.83561643835617]\n",
      "Mean Accuracy: 91.096%\n"
     ]
    }
   ],
   "source": [
    "# Test logistic regression algorithm on the housing dataset\n",
    "seed(1)\n",
    "\n",
    "# load and prepare data\n",
    "filename = 'dataset/house_train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Adding column Salelabel for Saleprice greater or less than 180000\n",
    "df['SaleLabel'] = df['SalePrice'].map(lambda m:1 if m >180000 else 0)\n",
    "\n",
    "#Numerical column\n",
    "ds = data_numerical_feature(df)\n",
    "\n",
    "final_dataset=ds.values\n",
    "final_ds = final_dataset.tolist()\n",
    "\n",
    "for i in range(0,len(final_ds[0])):\n",
    "    str_column_to_float(final_ds, i)\n",
    "\n",
    "# normalize\n",
    "minmax = dataset_minmax(final_ds)\n",
    "normalize_dataset(final_ds, minmax)\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.03\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(final_ds, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print(\"/n\")\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89091f90",
   "metadata": {},
   "source": [
    "#Mean accuracy on the training data\n",
    "Scores: [91.78082191780823, 88.35616438356165, 90.41095890410958, 91.0958904109589, 93.83561643835617]\n",
    "Mean Accuracy: 91.096%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35f0dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.010, error=277.212\n",
      ">epoch=1, lrate=0.010, error=254.343\n",
      ">epoch=2, lrate=0.010, error=235.718\n",
      ">epoch=3, lrate=0.010, error=220.334\n",
      ">epoch=4, lrate=0.010, error=207.594\n",
      ">epoch=5, lrate=0.010, error=196.958\n",
      ">epoch=6, lrate=0.010, error=187.989\n",
      ">epoch=7, lrate=0.010, error=180.346\n",
      ">epoch=8, lrate=0.010, error=173.764\n",
      ">epoch=9, lrate=0.010, error=168.039\n",
      ">epoch=10, lrate=0.010, error=163.014\n",
      ">epoch=11, lrate=0.010, error=158.567\n",
      ">epoch=12, lrate=0.010, error=154.600\n",
      ">epoch=13, lrate=0.010, error=151.037\n",
      ">epoch=14, lrate=0.010, error=147.817\n",
      ">epoch=15, lrate=0.010, error=144.890\n",
      ">epoch=16, lrate=0.010, error=142.215\n",
      ">epoch=17, lrate=0.010, error=139.759\n",
      ">epoch=18, lrate=0.010, error=137.494\n",
      ">epoch=19, lrate=0.010, error=135.397\n",
      ">epoch=20, lrate=0.010, error=133.449\n",
      ">epoch=21, lrate=0.010, error=131.632\n",
      ">epoch=22, lrate=0.010, error=129.933\n",
      ">epoch=23, lrate=0.010, error=128.340\n",
      ">epoch=24, lrate=0.010, error=126.842\n",
      ">epoch=25, lrate=0.010, error=125.429\n",
      ">epoch=26, lrate=0.010, error=124.095\n",
      ">epoch=27, lrate=0.010, error=122.831\n",
      ">epoch=28, lrate=0.010, error=121.633\n",
      ">epoch=29, lrate=0.010, error=120.494\n",
      ">epoch=30, lrate=0.010, error=119.409\n",
      ">epoch=31, lrate=0.010, error=118.375\n",
      ">epoch=32, lrate=0.010, error=117.387\n",
      ">epoch=33, lrate=0.010, error=116.442\n",
      ">epoch=34, lrate=0.010, error=115.537\n",
      ">epoch=35, lrate=0.010, error=114.669\n",
      ">epoch=36, lrate=0.010, error=113.836\n",
      ">epoch=37, lrate=0.010, error=113.035\n",
      ">epoch=38, lrate=0.010, error=112.264\n",
      ">epoch=39, lrate=0.010, error=111.521\n",
      ">epoch=40, lrate=0.010, error=110.805\n",
      ">epoch=41, lrate=0.010, error=110.114\n",
      ">epoch=42, lrate=0.010, error=109.446\n",
      ">epoch=43, lrate=0.010, error=108.801\n",
      ">epoch=44, lrate=0.010, error=108.176\n",
      ">epoch=45, lrate=0.010, error=107.571\n",
      ">epoch=46, lrate=0.010, error=106.985\n",
      ">epoch=47, lrate=0.010, error=106.417\n",
      ">epoch=48, lrate=0.010, error=105.865\n",
      ">epoch=49, lrate=0.010, error=105.329\n",
      "\n",
      "\n",
      "Expected=0.000, Predicted=0.604 [1]\n",
      "Expected=1.000, Predicted=0.787 [1]\n",
      "Expected=0.000, Predicted=0.085 [0]\n",
      "Expected=0.000, Predicted=0.239 [0]\n",
      "Expected=1.000, Predicted=0.927 [1]\n",
      "Expected=1.000, Predicted=0.856 [1]\n",
      "Expected=1.000, Predicted=0.785 [1]\n",
      "Expected=0.000, Predicted=0.094 [0]\n",
      "Expected=0.000, Predicted=0.605 [1]\n",
      "Expected=1.000, Predicted=0.336 [0]\n",
      "Expected=0.000, Predicted=0.403 [0]\n",
      "Expected=0.000, Predicted=0.396 [0]\n",
      "Expected=1.000, Predicted=0.807 [1]\n",
      "Expected=0.000, Predicted=0.042 [0]\n",
      "Expected=1.000, Predicted=0.562 [1]\n",
      "Expected=0.000, Predicted=0.493 [0]\n",
      "Expected=1.000, Predicted=0.835 [1]\n",
      "Expected=0.000, Predicted=0.156 [0]\n",
      "Expected=0.000, Predicted=0.452 [0]\n",
      "Expected=0.000, Predicted=0.554 [1]\n",
      "Expected=1.000, Predicted=0.982 [1]\n",
      "Expected=0.000, Predicted=0.175 [0]\n",
      "Expected=0.000, Predicted=0.144 [0]\n",
      "Expected=0.000, Predicted=0.194 [0]\n",
      "Expected=1.000, Predicted=0.386 [0]\n",
      "Expected=0.000, Predicted=0.377 [0]\n",
      "Expected=1.000, Predicted=0.235 [0]\n",
      "Expected=0.000, Predicted=0.022 [0]\n",
      "Expected=0.000, Predicted=0.333 [0]\n",
      "Expected=1.000, Predicted=0.394 [0]\n",
      "Expected=0.000, Predicted=0.079 [0]\n",
      "Expected=0.000, Predicted=0.390 [0]\n",
      "Expected=0.000, Predicted=0.141 [0]\n",
      "Expected=0.000, Predicted=0.107 [0]\n",
      "Expected=0.000, Predicted=0.190 [0]\n",
      "Expected=0.000, Predicted=0.046 [0]\n",
      "Expected=0.000, Predicted=0.302 [0]\n",
      "Expected=1.000, Predicted=0.704 [1]\n",
      "Expected=1.000, Predicted=0.887 [1]\n",
      "Expected=0.000, Predicted=0.358 [0]\n",
      "Expected=1.000, Predicted=0.541 [1]\n",
      "Expected=0.000, Predicted=0.142 [0]\n",
      "Expected=0.000, Predicted=0.087 [0]\n",
      "Expected=0.000, Predicted=0.096 [0]\n",
      "Expected=1.000, Predicted=0.623 [1]\n",
      "Expected=1.000, Predicted=0.632 [1]\n",
      "Expected=1.000, Predicted=0.801 [1]\n",
      "Expected=0.000, Predicted=0.132 [0]\n",
      "Expected=0.000, Predicted=0.132 [0]\n",
      "Expected=0.000, Predicted=0.447 [0]\n",
      "Expected=1.000, Predicted=0.606 [1]\n",
      "Expected=0.000, Predicted=0.028 [0]\n",
      "Expected=0.000, Predicted=0.515 [1]\n",
      "Expected=0.000, Predicted=0.181 [0]\n",
      "Expected=1.000, Predicted=0.711 [1]\n",
      "Expected=0.000, Predicted=0.136 [0]\n",
      "Expected=1.000, Predicted=0.550 [1]\n",
      "Expected=0.000, Predicted=0.447 [0]\n",
      "Expected=0.000, Predicted=0.149 [0]\n",
      "Expected=0.000, Predicted=0.212 [0]\n",
      "Expected=0.000, Predicted=0.134 [0]\n",
      "Expected=0.000, Predicted=0.462 [0]\n",
      "Expected=0.000, Predicted=0.290 [0]\n",
      "Expected=1.000, Predicted=0.626 [1]\n",
      "Expected=1.000, Predicted=0.702 [1]\n",
      "Expected=1.000, Predicted=0.301 [0]\n",
      "Expected=1.000, Predicted=0.734 [1]\n",
      "Expected=1.000, Predicted=0.576 [1]\n",
      "Expected=0.000, Predicted=0.311 [0]\n",
      "Expected=1.000, Predicted=0.710 [1]\n",
      "Expected=0.000, Predicted=0.059 [0]\n",
      "Expected=0.000, Predicted=0.169 [0]\n",
      "Expected=0.000, Predicted=0.087 [0]\n",
      "Expected=0.000, Predicted=0.062 [0]\n",
      "Expected=0.000, Predicted=0.556 [1]\n",
      "Expected=1.000, Predicted=0.614 [1]\n",
      "Expected=1.000, Predicted=0.717 [1]\n",
      "Expected=0.000, Predicted=0.102 [0]\n",
      "Expected=1.000, Predicted=0.417 [0]\n",
      "Expected=1.000, Predicted=0.665 [1]\n",
      "Expected=1.000, Predicted=0.832 [1]\n",
      "Expected=1.000, Predicted=0.811 [1]\n",
      "Expected=1.000, Predicted=0.254 [0]\n",
      "Expected=1.000, Predicted=0.455 [0]\n",
      "Expected=0.000, Predicted=0.218 [0]\n",
      "Expected=0.000, Predicted=0.059 [0]\n",
      "Expected=0.000, Predicted=0.310 [0]\n",
      "Expected=0.000, Predicted=0.313 [0]\n",
      "Expected=1.000, Predicted=0.894 [1]\n",
      "Expected=0.000, Predicted=0.154 [0]\n",
      "Expected=0.000, Predicted=0.167 [0]\n",
      "Expected=0.000, Predicted=0.058 [0]\n",
      "Expected=0.000, Predicted=0.059 [0]\n",
      "Expected=0.000, Predicted=0.074 [0]\n",
      "Expected=1.000, Predicted=0.866 [1]\n",
      "Expected=0.000, Predicted=0.193 [0]\n",
      "Expected=0.000, Predicted=0.330 [0]\n",
      "Expected=1.000, Predicted=0.455 [0]\n",
      "Expected=1.000, Predicted=0.137 [0]\n",
      "Expected=1.000, Predicted=0.551 [1]\n",
      "Expected=1.000, Predicted=0.820 [1]\n",
      "Expected=0.000, Predicted=0.582 [1]\n",
      "Expected=0.000, Predicted=0.106 [0]\n",
      "Expected=0.000, Predicted=0.146 [0]\n",
      "Expected=0.000, Predicted=0.098 [0]\n",
      "Expected=1.000, Predicted=0.914 [1]\n",
      "Expected=1.000, Predicted=0.400 [0]\n",
      "Expected=1.000, Predicted=0.483 [0]\n",
      "Expected=0.000, Predicted=0.064 [0]\n",
      "Expected=0.000, Predicted=0.092 [0]\n",
      "Expected=0.000, Predicted=0.544 [1]\n",
      "Expected=1.000, Predicted=0.488 [0]\n",
      "Expected=0.000, Predicted=0.086 [0]\n",
      "Expected=0.000, Predicted=0.036 [0]\n",
      "Expected=0.000, Predicted=0.085 [0]\n",
      "Expected=0.000, Predicted=0.280 [0]\n",
      "Expected=1.000, Predicted=0.900 [1]\n",
      "Expected=1.000, Predicted=0.891 [1]\n",
      "Expected=0.000, Predicted=0.110 [0]\n",
      "Expected=0.000, Predicted=0.069 [0]\n",
      "Expected=0.000, Predicted=0.364 [0]\n",
      "Expected=1.000, Predicted=0.946 [1]\n",
      "Expected=0.000, Predicted=0.038 [0]\n",
      "Expected=0.000, Predicted=0.342 [0]\n",
      "Expected=1.000, Predicted=0.860 [1]\n",
      "Expected=0.000, Predicted=0.544 [1]\n",
      "Expected=0.000, Predicted=0.091 [0]\n",
      "Expected=0.000, Predicted=0.713 [1]\n",
      "Expected=1.000, Predicted=0.815 [1]\n",
      "Expected=0.000, Predicted=0.580 [1]\n",
      "Expected=0.000, Predicted=0.068 [0]\n",
      "Expected=0.000, Predicted=0.560 [1]\n",
      "Expected=1.000, Predicted=0.402 [0]\n",
      "Expected=1.000, Predicted=0.531 [1]\n",
      "Expected=0.000, Predicted=0.128 [0]\n",
      "Expected=1.000, Predicted=0.596 [1]\n",
      "Expected=0.000, Predicted=0.032 [0]\n",
      "Expected=1.000, Predicted=0.715 [1]\n",
      "Expected=0.000, Predicted=0.086 [0]\n",
      "Expected=0.000, Predicted=0.265 [0]\n",
      "Expected=1.000, Predicted=0.570 [1]\n",
      "Expected=0.000, Predicted=0.112 [0]\n",
      "Expected=0.000, Predicted=0.123 [0]\n",
      "Expected=1.000, Predicted=0.964 [1]\n",
      "Expected=0.000, Predicted=0.644 [1]\n",
      "Expected=0.000, Predicted=0.122 [0]\n",
      "Expected=1.000, Predicted=0.581 [1]\n",
      "Expected=0.000, Predicted=0.405 [0]\n",
      "Expected=1.000, Predicted=0.889 [1]\n",
      "Expected=0.000, Predicted=0.206 [0]\n",
      "Expected=1.000, Predicted=0.882 [1]\n",
      "Expected=1.000, Predicted=0.202 [0]\n",
      "Expected=1.000, Predicted=0.473 [0]\n",
      "Expected=1.000, Predicted=0.518 [1]\n",
      "Expected=0.000, Predicted=0.111 [0]\n",
      "Expected=0.000, Predicted=0.186 [0]\n",
      "Expected=1.000, Predicted=0.213 [0]\n",
      "Expected=0.000, Predicted=0.297 [0]\n",
      "Expected=0.000, Predicted=0.342 [0]\n",
      "Expected=1.000, Predicted=0.921 [1]\n",
      "Expected=0.000, Predicted=0.020 [0]\n",
      "Expected=1.000, Predicted=0.914 [1]\n",
      "Expected=1.000, Predicted=0.930 [1]\n",
      "Expected=0.000, Predicted=0.444 [0]\n",
      "Expected=1.000, Predicted=0.644 [1]\n",
      "Expected=1.000, Predicted=0.431 [0]\n",
      "Expected=0.000, Predicted=0.365 [0]\n",
      "Expected=0.000, Predicted=0.610 [1]\n",
      "Expected=1.000, Predicted=0.861 [1]\n",
      "Expected=0.000, Predicted=0.426 [0]\n",
      "Expected=0.000, Predicted=0.077 [0]\n",
      "Expected=1.000, Predicted=0.495 [0]\n",
      "Expected=0.000, Predicted=0.210 [0]\n",
      "Expected=1.000, Predicted=0.653 [1]\n",
      "Expected=0.000, Predicted=0.114 [0]\n",
      "Expected=0.000, Predicted=0.101 [0]\n",
      "Expected=0.000, Predicted=0.151 [0]\n",
      "Expected=1.000, Predicted=0.701 [1]\n",
      "Expected=1.000, Predicted=0.903 [1]\n",
      "Expected=0.000, Predicted=0.039 [0]\n",
      "Expected=0.000, Predicted=0.100 [0]\n",
      "Expected=0.000, Predicted=0.141 [0]\n",
      "Expected=0.000, Predicted=0.391 [0]\n",
      "Expected=1.000, Predicted=0.626 [1]\n",
      "Expected=0.000, Predicted=0.038 [0]\n",
      "Expected=1.000, Predicted=0.974 [1]\n",
      "Expected=1.000, Predicted=0.650 [1]\n",
      "Expected=0.000, Predicted=0.401 [0]\n",
      "Expected=0.000, Predicted=0.125 [0]\n",
      "Expected=0.000, Predicted=0.096 [0]\n",
      "Expected=0.000, Predicted=0.115 [0]\n",
      "Expected=0.000, Predicted=0.068 [0]\n",
      "Expected=0.000, Predicted=0.036 [0]\n",
      "Expected=0.000, Predicted=0.120 [0]\n",
      "Expected=1.000, Predicted=0.831 [1]\n",
      "Expected=0.000, Predicted=0.340 [0]\n",
      "Expected=0.000, Predicted=0.036 [0]\n",
      "Expected=0.000, Predicted=0.140 [0]\n",
      "Expected=1.000, Predicted=0.796 [1]\n",
      "Expected=1.000, Predicted=0.735 [1]\n",
      "Expected=1.000, Predicted=0.648 [1]\n",
      "Expected=1.000, Predicted=0.938 [1]\n",
      "Expected=1.000, Predicted=0.594 [1]\n",
      "Expected=1.000, Predicted=0.969 [1]\n",
      "Expected=1.000, Predicted=0.838 [1]\n",
      "Expected=0.000, Predicted=0.241 [0]\n",
      "Expected=0.000, Predicted=0.165 [0]\n",
      "Expected=1.000, Predicted=0.954 [1]\n",
      "Expected=0.000, Predicted=0.098 [0]\n",
      "Expected=0.000, Predicted=0.221 [0]\n",
      "Expected=0.000, Predicted=0.077 [0]\n",
      "Expected=0.000, Predicted=0.053 [0]\n",
      "Expected=0.000, Predicted=0.079 [0]\n",
      "Expected=0.000, Predicted=0.068 [0]\n",
      "Expected=0.000, Predicted=0.317 [0]\n",
      "Expected=0.000, Predicted=0.281 [0]\n",
      "Expected=1.000, Predicted=0.838 [1]\n",
      "Expected=0.000, Predicted=0.049 [0]\n",
      "Expected=0.000, Predicted=0.057 [0]\n",
      "Expected=0.000, Predicted=0.237 [0]\n",
      "Expected=0.000, Predicted=0.128 [0]\n",
      "Expected=0.000, Predicted=0.423 [0]\n",
      "Expected=0.000, Predicted=0.054 [0]\n",
      "Expected=1.000, Predicted=0.844 [1]\n",
      "Expected=0.000, Predicted=0.017 [0]\n",
      "Expected=0.000, Predicted=0.045 [0]\n",
      "Expected=1.000, Predicted=0.790 [1]\n",
      "Expected=0.000, Predicted=0.214 [0]\n",
      "Expected=1.000, Predicted=0.890 [1]\n",
      "Expected=0.000, Predicted=0.083 [0]\n",
      "Expected=1.000, Predicted=0.718 [1]\n",
      "Expected=0.000, Predicted=0.143 [0]\n",
      "Expected=0.000, Predicted=0.184 [0]\n",
      "Expected=1.000, Predicted=0.528 [1]\n",
      "Expected=0.000, Predicted=0.078 [0]\n",
      "Expected=0.000, Predicted=0.188 [0]\n",
      "Expected=1.000, Predicted=0.697 [1]\n",
      "Expected=0.000, Predicted=0.133 [0]\n",
      "Expected=1.000, Predicted=0.859 [1]\n",
      "Expected=0.000, Predicted=0.190 [0]\n",
      "Expected=0.000, Predicted=0.065 [0]\n",
      "Expected=0.000, Predicted=0.181 [0]\n",
      "Expected=1.000, Predicted=0.357 [0]\n",
      "Expected=1.000, Predicted=0.887 [1]\n",
      "Expected=1.000, Predicted=0.920 [1]\n",
      "Expected=0.000, Predicted=0.641 [1]\n",
      "Expected=0.000, Predicted=0.347 [0]\n",
      "Expected=1.000, Predicted=0.687 [1]\n",
      "Expected=0.000, Predicted=0.202 [0]\n",
      "Expected=0.000, Predicted=0.710 [1]\n",
      "Expected=1.000, Predicted=0.670 [1]\n",
      "Expected=1.000, Predicted=0.637 [1]\n",
      "Expected=0.000, Predicted=0.114 [0]\n",
      "Expected=0.000, Predicted=0.135 [0]\n",
      "Expected=0.000, Predicted=0.220 [0]\n",
      "Expected=0.000, Predicted=0.303 [0]\n",
      "Expected=1.000, Predicted=0.932 [1]\n",
      "Expected=0.000, Predicted=0.220 [0]\n",
      "Expected=1.000, Predicted=0.597 [1]\n",
      "Expected=0.000, Predicted=0.292 [0]\n",
      "Expected=0.000, Predicted=0.039 [0]\n",
      "Expected=1.000, Predicted=0.622 [1]\n",
      "Expected=0.000, Predicted=0.163 [0]\n",
      "Expected=0.000, Predicted=0.026 [0]\n",
      "Expected=0.000, Predicted=0.152 [0]\n",
      "Expected=0.000, Predicted=0.049 [0]\n",
      "Expected=0.000, Predicted=0.236 [0]\n",
      "Expected=0.000, Predicted=0.171 [0]\n",
      "Expected=0.000, Predicted=0.069 [0]\n",
      "Expected=0.000, Predicted=0.131 [0]\n",
      "Expected=0.000, Predicted=0.173 [0]\n",
      "Expected=0.000, Predicted=0.069 [0]\n",
      "Expected=0.000, Predicted=0.209 [0]\n",
      "Expected=0.000, Predicted=0.156 [0]\n",
      "Expected=0.000, Predicted=0.419 [0]\n",
      "Expected=1.000, Predicted=0.733 [1]\n",
      "Expected=0.000, Predicted=0.086 [0]\n",
      "Expected=0.000, Predicted=0.718 [1]\n",
      "Expected=0.000, Predicted=0.100 [0]\n",
      "Expected=0.000, Predicted=0.174 [0]\n",
      "Expected=0.000, Predicted=0.096 [0]\n",
      "Expected=0.000, Predicted=0.045 [0]\n",
      "Expected=1.000, Predicted=0.893 [1]\n",
      "Expected=0.000, Predicted=0.464 [0]\n",
      "Expected=0.000, Predicted=0.687 [1]\n",
      "Expected=1.000, Predicted=0.894 [1]\n",
      "Expected=0.000, Predicted=0.382 [0]\n",
      "Expected=0.000, Predicted=0.053 [0]\n",
      "Expected=1.000, Predicted=0.440 [0]\n",
      "Expected=1.000, Predicted=0.910 [1]\n",
      "Expected=0.000, Predicted=0.548 [1]\n",
      "Expected=0.000, Predicted=0.147 [0]\n"
     ]
    }
   ],
   "source": [
    "# Test Splitting training data into training set and test set\n",
    "\n",
    "l_rate = 0.01\n",
    "n_epoch = 50\n",
    "train_ds, test_ds = train_test_split(final_ds, test_size = 0.2, random_state = 10)\n",
    "w = weights_sgd(train_ds,l_rate,n_epoch)\n",
    "#print(w)\n",
    "    \n",
    "print('\\n')\n",
    "sold_status = []\n",
    "for row in test_ds:\n",
    "    yhat = predict(row, w)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f [%d]\" % (row[-1], yhat, round(yhat)))\n",
    "    if round(yhat) == 1:\n",
    "        status = \"Sold\"\n",
    "    else:\n",
    "        status = \"Not Sold\"\n",
    "    sold_status.append([round(row[-1]),round(yhat),status])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe2e21",
   "metadata": {},
   "source": [
    "#Sold Status on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844cf46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Status</th>\n",
       "      <th>Predicted Status</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Sold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Status  Predicted Status    Status\n",
       "0                0                 1      Sold\n",
       "1                1                 1      Sold\n",
       "2                0                 0  Not Sold\n",
       "3                0                 0  Not Sold\n",
       "4                1                 1      Sold\n",
       "..             ...               ...       ...\n",
       "287              0                 0  Not Sold\n",
       "288              1                 0  Not Sold\n",
       "289              1                 1      Sold\n",
       "290              0                 1      Sold\n",
       "291              0                 0  Not Sold\n",
       "\n",
       "[292 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sold_status , columns = [\"Actual Status\", \"Predicted Status\" , \"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b970ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.030, error=55.017\n",
      ">epoch=1, lrate=0.030, error=52.303\n",
      ">epoch=2, lrate=0.030, error=49.978\n",
      ">epoch=3, lrate=0.030, error=47.788\n",
      ">epoch=4, lrate=0.030, error=45.804\n",
      ">epoch=5, lrate=0.030, error=44.025\n",
      ">epoch=6, lrate=0.030, error=42.431\n",
      ">epoch=7, lrate=0.030, error=41.001\n",
      ">epoch=8, lrate=0.030, error=39.717\n",
      ">epoch=9, lrate=0.030, error=38.559\n",
      ">epoch=10, lrate=0.030, error=37.512\n",
      ">epoch=11, lrate=0.030, error=36.562\n",
      ">epoch=12, lrate=0.030, error=35.696\n",
      ">epoch=13, lrate=0.030, error=34.905\n",
      ">epoch=14, lrate=0.030, error=34.178\n",
      ">epoch=15, lrate=0.030, error=33.510\n",
      ">epoch=16, lrate=0.030, error=32.892\n",
      ">epoch=17, lrate=0.030, error=32.319\n",
      ">epoch=18, lrate=0.030, error=31.787\n",
      ">epoch=19, lrate=0.030, error=31.291\n",
      ">epoch=20, lrate=0.030, error=30.827\n",
      ">epoch=21, lrate=0.030, error=30.392\n",
      ">epoch=22, lrate=0.030, error=29.983\n",
      ">epoch=23, lrate=0.030, error=29.598\n",
      ">epoch=24, lrate=0.030, error=29.235\n",
      ">epoch=25, lrate=0.030, error=28.891\n",
      ">epoch=26, lrate=0.030, error=28.566\n",
      ">epoch=27, lrate=0.030, error=28.256\n",
      ">epoch=28, lrate=0.030, error=27.962\n",
      ">epoch=29, lrate=0.030, error=27.682\n",
      ">epoch=30, lrate=0.030, error=27.414\n",
      ">epoch=31, lrate=0.030, error=27.159\n",
      ">epoch=32, lrate=0.030, error=26.914\n",
      ">epoch=33, lrate=0.030, error=26.680\n",
      ">epoch=34, lrate=0.030, error=26.455\n",
      ">epoch=35, lrate=0.030, error=26.240\n",
      ">epoch=36, lrate=0.030, error=26.032\n",
      ">epoch=37, lrate=0.030, error=25.832\n",
      ">epoch=38, lrate=0.030, error=25.640\n",
      ">epoch=39, lrate=0.030, error=25.454\n",
      ">epoch=40, lrate=0.030, error=25.275\n",
      ">epoch=41, lrate=0.030, error=25.102\n",
      ">epoch=42, lrate=0.030, error=24.934\n",
      ">epoch=43, lrate=0.030, error=24.772\n",
      ">epoch=44, lrate=0.030, error=24.616\n",
      ">epoch=45, lrate=0.030, error=24.464\n",
      ">epoch=46, lrate=0.030, error=24.316\n",
      ">epoch=47, lrate=0.030, error=24.173\n",
      ">epoch=48, lrate=0.030, error=24.034\n",
      ">epoch=49, lrate=0.030, error=23.899\n",
      ">epoch=0, lrate=0.030, error=53.845\n",
      ">epoch=1, lrate=0.030, error=50.394\n",
      ">epoch=2, lrate=0.030, error=48.161\n",
      ">epoch=3, lrate=0.030, error=46.107\n",
      ">epoch=4, lrate=0.030, error=44.233\n",
      ">epoch=5, lrate=0.030, error=42.539\n",
      ">epoch=6, lrate=0.030, error=41.013\n",
      ">epoch=7, lrate=0.030, error=39.640\n",
      ">epoch=8, lrate=0.030, error=38.402\n",
      ">epoch=9, lrate=0.030, error=37.285\n",
      ">epoch=10, lrate=0.030, error=36.274\n",
      ">epoch=11, lrate=0.030, error=35.356\n",
      ">epoch=12, lrate=0.030, error=34.521\n",
      ">epoch=13, lrate=0.030, error=33.757\n",
      ">epoch=14, lrate=0.030, error=33.057\n",
      ">epoch=15, lrate=0.030, error=32.414\n",
      ">epoch=16, lrate=0.030, error=31.821\n",
      ">epoch=17, lrate=0.030, error=31.272\n",
      ">epoch=18, lrate=0.030, error=30.762\n",
      ">epoch=19, lrate=0.030, error=30.288\n",
      ">epoch=20, lrate=0.030, error=29.845\n",
      ">epoch=21, lrate=0.030, error=29.432\n",
      ">epoch=22, lrate=0.030, error=29.043\n",
      ">epoch=23, lrate=0.030, error=28.679\n",
      ">epoch=24, lrate=0.030, error=28.335\n",
      ">epoch=25, lrate=0.030, error=28.011\n",
      ">epoch=26, lrate=0.030, error=27.704\n",
      ">epoch=27, lrate=0.030, error=27.413\n",
      ">epoch=28, lrate=0.030, error=27.137\n",
      ">epoch=29, lrate=0.030, error=26.875\n",
      ">epoch=30, lrate=0.030, error=26.625\n",
      ">epoch=31, lrate=0.030, error=26.386\n",
      ">epoch=32, lrate=0.030, error=26.159\n",
      ">epoch=33, lrate=0.030, error=25.941\n",
      ">epoch=34, lrate=0.030, error=25.733\n",
      ">epoch=35, lrate=0.030, error=25.533\n",
      ">epoch=36, lrate=0.030, error=25.341\n",
      ">epoch=37, lrate=0.030, error=25.156\n",
      ">epoch=38, lrate=0.030, error=24.979\n",
      ">epoch=39, lrate=0.030, error=24.808\n",
      ">epoch=40, lrate=0.030, error=24.643\n",
      ">epoch=41, lrate=0.030, error=24.484\n",
      ">epoch=42, lrate=0.030, error=24.331\n",
      ">epoch=43, lrate=0.030, error=24.183\n",
      ">epoch=44, lrate=0.030, error=24.039\n",
      ">epoch=45, lrate=0.030, error=23.900\n",
      ">epoch=46, lrate=0.030, error=23.766\n",
      ">epoch=47, lrate=0.030, error=23.635\n",
      ">epoch=48, lrate=0.030, error=23.509\n",
      ">epoch=49, lrate=0.030, error=23.386\n",
      ">epoch=0, lrate=0.030, error=55.669\n",
      ">epoch=1, lrate=0.030, error=52.584\n",
      ">epoch=2, lrate=0.030, error=49.983\n",
      ">epoch=3, lrate=0.030, error=47.626\n",
      ">epoch=4, lrate=0.030, error=45.531\n",
      ">epoch=5, lrate=0.030, error=43.675\n",
      ">epoch=6, lrate=0.030, error=42.031\n",
      ">epoch=7, lrate=0.030, error=40.570\n",
      ">epoch=8, lrate=0.030, error=39.268\n",
      ">epoch=9, lrate=0.030, error=38.102\n",
      ">epoch=10, lrate=0.030, error=37.053\n",
      ">epoch=11, lrate=0.030, error=36.106\n",
      ">epoch=12, lrate=0.030, error=35.247\n",
      ">epoch=13, lrate=0.030, error=34.464\n",
      ">epoch=14, lrate=0.030, error=33.749\n",
      ">epoch=15, lrate=0.030, error=33.091\n",
      ">epoch=16, lrate=0.030, error=32.486\n",
      ">epoch=17, lrate=0.030, error=31.925\n",
      ">epoch=18, lrate=0.030, error=31.405\n",
      ">epoch=19, lrate=0.030, error=30.921\n",
      ">epoch=20, lrate=0.030, error=30.469\n",
      ">epoch=21, lrate=0.030, error=30.046\n",
      ">epoch=22, lrate=0.030, error=29.649\n",
      ">epoch=23, lrate=0.030, error=29.275\n",
      ">epoch=24, lrate=0.030, error=28.923\n",
      ">epoch=25, lrate=0.030, error=28.590\n",
      ">epoch=26, lrate=0.030, error=28.275\n",
      ">epoch=27, lrate=0.030, error=27.976\n",
      ">epoch=28, lrate=0.030, error=27.691\n",
      ">epoch=29, lrate=0.030, error=27.421\n",
      ">epoch=30, lrate=0.030, error=27.163\n",
      ">epoch=31, lrate=0.030, error=26.917\n",
      ">epoch=32, lrate=0.030, error=26.681\n",
      ">epoch=33, lrate=0.030, error=26.456\n",
      ">epoch=34, lrate=0.030, error=26.240\n",
      ">epoch=35, lrate=0.030, error=26.032\n",
      ">epoch=36, lrate=0.030, error=25.833\n",
      ">epoch=37, lrate=0.030, error=25.642\n",
      ">epoch=38, lrate=0.030, error=25.457\n",
      ">epoch=39, lrate=0.030, error=25.279\n",
      ">epoch=40, lrate=0.030, error=25.108\n",
      ">epoch=41, lrate=0.030, error=24.942\n",
      ">epoch=42, lrate=0.030, error=24.782\n",
      ">epoch=43, lrate=0.030, error=24.628\n",
      ">epoch=44, lrate=0.030, error=24.478\n",
      ">epoch=45, lrate=0.030, error=24.333\n",
      ">epoch=46, lrate=0.030, error=24.193\n",
      ">epoch=47, lrate=0.030, error=24.056\n",
      ">epoch=48, lrate=0.030, error=23.924\n",
      ">epoch=49, lrate=0.030, error=23.796\n",
      ">epoch=0, lrate=0.030, error=56.096\n",
      ">epoch=1, lrate=0.030, error=52.900\n",
      ">epoch=2, lrate=0.030, error=50.203\n",
      ">epoch=3, lrate=0.030, error=47.809\n",
      ">epoch=4, lrate=0.030, error=45.706\n",
      ">epoch=5, lrate=0.030, error=43.859\n",
      ">epoch=6, lrate=0.030, error=42.235\n",
      ">epoch=7, lrate=0.030, error=40.802\n",
      ">epoch=8, lrate=0.030, error=39.531\n",
      ">epoch=9, lrate=0.030, error=38.398\n",
      ">epoch=10, lrate=0.030, error=37.384\n",
      ">epoch=11, lrate=0.030, error=36.472\n",
      ">epoch=12, lrate=0.030, error=35.647\n",
      ">epoch=13, lrate=0.030, error=34.897\n",
      ">epoch=14, lrate=0.030, error=34.213\n",
      ">epoch=15, lrate=0.030, error=33.586\n",
      ">epoch=16, lrate=0.030, error=33.008\n",
      ">epoch=17, lrate=0.030, error=32.475\n",
      ">epoch=18, lrate=0.030, error=31.981\n",
      ">epoch=19, lrate=0.030, error=31.521\n",
      ">epoch=20, lrate=0.030, error=31.092\n",
      ">epoch=21, lrate=0.030, error=30.690\n",
      ">epoch=22, lrate=0.030, error=30.314\n",
      ">epoch=23, lrate=0.030, error=29.959\n",
      ">epoch=24, lrate=0.030, error=29.625\n",
      ">epoch=25, lrate=0.030, error=29.309\n",
      ">epoch=26, lrate=0.030, error=29.010\n",
      ">epoch=27, lrate=0.030, error=28.727\n",
      ">epoch=28, lrate=0.030, error=28.457\n",
      ">epoch=29, lrate=0.030, error=28.200\n",
      ">epoch=30, lrate=0.030, error=27.955\n",
      ">epoch=31, lrate=0.030, error=27.721\n",
      ">epoch=32, lrate=0.030, error=27.497\n",
      ">epoch=33, lrate=0.030, error=27.283\n",
      ">epoch=34, lrate=0.030, error=27.077\n",
      ">epoch=35, lrate=0.030, error=26.880\n",
      ">epoch=36, lrate=0.030, error=26.690\n",
      ">epoch=37, lrate=0.030, error=26.507\n",
      ">epoch=38, lrate=0.030, error=26.331\n",
      ">epoch=39, lrate=0.030, error=26.161\n",
      ">epoch=40, lrate=0.030, error=25.997\n",
      ">epoch=41, lrate=0.030, error=25.839\n",
      ">epoch=42, lrate=0.030, error=25.686\n",
      ">epoch=43, lrate=0.030, error=25.538\n",
      ">epoch=44, lrate=0.030, error=25.394\n",
      ">epoch=45, lrate=0.030, error=25.255\n",
      ">epoch=46, lrate=0.030, error=25.120\n",
      ">epoch=47, lrate=0.030, error=24.989\n",
      ">epoch=48, lrate=0.030, error=24.862\n",
      ">epoch=49, lrate=0.030, error=24.738\n",
      ">epoch=0, lrate=0.030, error=55.575\n",
      ">epoch=1, lrate=0.030, error=52.736\n",
      ">epoch=2, lrate=0.030, error=50.363\n",
      ">epoch=3, lrate=0.030, error=48.171\n",
      ">epoch=4, lrate=0.030, error=46.205\n",
      ">epoch=5, lrate=0.030, error=44.453\n",
      ">epoch=6, lrate=0.030, error=42.892\n",
      ">epoch=7, lrate=0.030, error=41.498\n",
      ">epoch=8, lrate=0.030, error=40.250\n",
      ">epoch=9, lrate=0.030, error=39.128\n",
      ">epoch=10, lrate=0.030, error=38.115\n",
      ">epoch=11, lrate=0.030, error=37.197\n",
      ">epoch=12, lrate=0.030, error=36.362\n",
      ">epoch=13, lrate=0.030, error=35.600\n",
      ">epoch=14, lrate=0.030, error=34.900\n",
      ">epoch=15, lrate=0.030, error=34.256\n",
      ">epoch=16, lrate=0.030, error=33.662\n",
      ">epoch=17, lrate=0.030, error=33.111\n",
      ">epoch=18, lrate=0.030, error=32.598\n",
      ">epoch=19, lrate=0.030, error=32.120\n",
      ">epoch=20, lrate=0.030, error=31.673\n",
      ">epoch=21, lrate=0.030, error=31.254\n",
      ">epoch=22, lrate=0.030, error=30.860\n",
      ">epoch=23, lrate=0.030, error=30.489\n",
      ">epoch=24, lrate=0.030, error=30.138\n",
      ">epoch=25, lrate=0.030, error=29.807\n",
      ">epoch=26, lrate=0.030, error=29.492\n",
      ">epoch=27, lrate=0.030, error=29.194\n",
      ">epoch=28, lrate=0.030, error=28.909\n",
      ">epoch=29, lrate=0.030, error=28.638\n",
      ">epoch=30, lrate=0.030, error=28.380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=31, lrate=0.030, error=28.132\n",
      ">epoch=32, lrate=0.030, error=27.896\n",
      ">epoch=33, lrate=0.030, error=27.669\n",
      ">epoch=34, lrate=0.030, error=27.451\n",
      ">epoch=35, lrate=0.030, error=27.242\n",
      ">epoch=36, lrate=0.030, error=27.041\n",
      ">epoch=37, lrate=0.030, error=26.847\n",
      ">epoch=38, lrate=0.030, error=26.660\n",
      ">epoch=39, lrate=0.030, error=26.480\n",
      ">epoch=40, lrate=0.030, error=26.306\n",
      ">epoch=41, lrate=0.030, error=26.138\n",
      ">epoch=42, lrate=0.030, error=25.975\n",
      ">epoch=43, lrate=0.030, error=25.817\n",
      ">epoch=44, lrate=0.030, error=25.665\n",
      ">epoch=45, lrate=0.030, error=25.517\n",
      ">epoch=46, lrate=0.030, error=25.373\n",
      ">epoch=47, lrate=0.030, error=25.233\n",
      ">epoch=48, lrate=0.030, error=25.098\n",
      ">epoch=49, lrate=0.030, error=24.966\n",
      "\n",
      "\n",
      "Scores: [84.48275862068965, 77.58620689655173, 84.48275862068965, 89.65517241379311, 93.10344827586206]\n",
      "Mean Accuracy: 85.862%\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.03\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(test_ds, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "\n",
    "print('\\n')\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad559e5",
   "metadata": {},
   "source": [
    "#Question 4, Part 1\n",
    "\n",
    "Scores: [84.48275862068965, 77.58620689655173, 84.48275862068965, 89.65517241379311, 93.10344827586206]\n",
    "Mean Accuracy: 85.862%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
